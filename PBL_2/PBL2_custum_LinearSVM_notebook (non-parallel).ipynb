{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import struct\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "which is GPL licensed.\n",
    "\"\"\"\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'mnist_new-patterns-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'mnist_new-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 'mnist_new_test-patterns-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'mnist_new_test-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise Exception(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8)) ## 바이너리 데이터를 추출하면서 >||로 구분하는 듯함. flbl.read라는 퍼버에 저장\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8) #np 형식으로 버퍼의 내용을 저장.\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classifier\n",
    "\"\"\"\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "class StochasticClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, eta=0.01, n_iter=1000, b_size=1, lamb=0.001, random_state=None, shuffle=True):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.b_size = b_size  # batch size\n",
    "        self.lamb = lamb  # lambda == c\n",
    "        self.random_state = random_state\n",
    "        self.shuffle = shuffle\n",
    "        self.labels = None\n",
    "        self.w_ = {}\n",
    "        self.w_bar_ = {}\n",
    "        self.b_ = {}  # vector\n",
    "        self.b_bar_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.labels = np.unique(y)  # list will be array (0, ....9)\n",
    "\n",
    "        for label in self.labels:  # do classify every class.\n",
    "            self._initialize_weights(label, X.shape[1])\n",
    "            self.b_[label] = 0\n",
    "            ova_y = []\n",
    "\n",
    "            for xi, yi in zip(X, y):  # make new label for OvA.\n",
    "                if label == yi:\n",
    "                    ova_y.append(1)\n",
    "                else:\n",
    "                    ova_y.append(-1)\n",
    "\n",
    "            n_list = []\n",
    "\n",
    "            for iteration in range(self.n_iter):\n",
    "                samples = []\n",
    "\n",
    "                for i in range(self.b_size):\n",
    "                    if not n_list:  # list empty\n",
    "                        n_list = self.shuffle_index(len(y))\n",
    "                    n = n_list.pop()\n",
    "                    samples.append((X[n], ova_y[n]))\n",
    "\n",
    "                self._update_weights(label, iteration, samples, X.shape[1])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def shuffle_index(self, n):\n",
    "        n_list = [i for i in range(0, n)]\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(n_list)  # just shuffle index\n",
    "\n",
    "        return n_list\n",
    "\n",
    "    def _initialize_weights(self, label, m):  # 작은 값으로 weight 값 초기화\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_[label] = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)\n",
    "\n",
    "    def _update_weights(self, label, iteration, samples, m):\n",
    "        w = [0 for num in range(m)]\n",
    "        b = 0\n",
    "\n",
    "        for xi, y in samples:  # samples[0] 데이터, samples[1] 라벨\n",
    "            output = self.net_input_for_learning(label, xi)\n",
    "            if y * output <= 1:\n",
    "                w += self.eta * xi.dot(y)\n",
    "                b += self.eta * y\n",
    "\n",
    "        self.w_[label][1:] += np.divide(w, self.b_size) - self.lamb * self.w_[label][1:]\n",
    "        self.b_[label] += b / self.b_size\n",
    "\n",
    "        if iteration == 0:\n",
    "            self.w_bar_[label] = copy.copy(self.w_[label])\n",
    "            self.b_bar_[label] = copy.copy(self.b_[label])\n",
    "        else:\n",
    "            self.w_bar_[label][1:] = np.multiply(iteration/(iteration+1), self.w_bar_[label][1:]) + np.multiply(1/(iteration+1), self.w_[label][1:])\n",
    "            self.b_bar_[label] = iteration/(iteration+1)*self.b_bar_[label] + 1/(iteration+1)*self.b_[label]\n",
    "\n",
    "    def net_input_for_learning(self, label, X):\n",
    "        return np.dot(self.w_[label][1:], X) + self.b_[label]\n",
    "\n",
    "    def net_input_for_predict(self, label, X):\n",
    "        return np.dot(self.w_bar_[label][1:], X) + self.b_bar_[label]\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for xi in X:\n",
    "            predict_output = {}\n",
    "\n",
    "            for label in self.labels:\n",
    "                predict_output[label] = self.net_input_for_predict(label, xi)\n",
    "\n",
    "            output = None\n",
    "\n",
    "            for item in predict_output:\n",
    "                if not output:\n",
    "                    output = item\n",
    "                else:\n",
    "                    if predict_output[output] < predict_output[item]:\n",
    "                        output = item\n",
    "            predictions.append(output)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feautures\n",
    "\"\"\"\n",
    "import random\n",
    "import copy\n",
    "\n",
    "def make_input_image_sharp(image_input, value): # 리턴 값은 그냥 펴진 스트링임.\n",
    "    new_image = []\n",
    "    image = np.reshape(image_input, 28*28)\n",
    "    for pixel in image:\n",
    "        if pixel >= value:\n",
    "            new_image.append(pixel)\n",
    "        else:\n",
    "            new_image.append(0)\n",
    "    return new_image\n",
    "\n",
    "def draw_to_end(image_input):\n",
    "    image = image_input\n",
    "    new_image = []\n",
    "    for row in image:\n",
    "        new_row = list(row)\n",
    "        threshold = 128\n",
    "        start_point = 0\n",
    "        last_point = 0\n",
    "        for i in range(len(row)):\n",
    "            if row[i] > threshold:\n",
    "                start_point = i\n",
    "                break\n",
    "        for i in reversed(range(len(row))):\n",
    "            if row[i] > threshold:\n",
    "                last_point = i\n",
    "                break\n",
    "        for i in range(start_point, last_point):\n",
    "            new_row[i] = 255\n",
    "        new_image += new_row\n",
    "    return new_image\n",
    "\n",
    "def draw_to_end_by_col(image_input):\n",
    "    image = copy.copy(image_input)\n",
    "    col_image = [[] for i in range(28)]\n",
    "    for row in image:\n",
    "        for item_n in range(len(row)):\n",
    "            col_image[item_n].append(row[item_n])\n",
    "    image = col_image\n",
    "    new_image = []\n",
    "    for row in image:\n",
    "        new_row = list(row)\n",
    "        threshold = 128\n",
    "        start_point = 0\n",
    "        last_point = 0\n",
    "        for i in range(len(row)):\n",
    "            if row[i] > threshold:\n",
    "                start_point = i\n",
    "                break\n",
    "        for i in reversed(range(len(row))):\n",
    "            if row[i] > threshold:\n",
    "                last_point = i\n",
    "                break\n",
    "        for i in range(start_point, last_point):\n",
    "            new_row[i] = 255\n",
    "        new_image += new_row\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def new_feature(image_input, length): #자기랑 하는 거 안 뺌. 곱하기 연산\n",
    "    new_ftr = []\n",
    "    for i in range(length):\n",
    "        for j in range(i, length):\n",
    "            new_ftr.append(image_input[i] * image_input[j])\n",
    "    return new_ftr\n",
    "\n",
    "\n",
    "def new_feature2(image_input, length): #자기랑 하는 거 안 뺌. 더하기 연산\n",
    "    new_ftr = []\n",
    "    for i in range(length):\n",
    "        for j in range(i, length):\n",
    "            new_ftr.append(image_input[i] + image_input[j])\n",
    "    return new_ftr\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "def add_new_features(original_features, new_features):\n",
    "    # 2차원 array 인 경우\n",
    "    if isinstance(new_features[0], list):\n",
    "        for i in new_features:\n",
    "            for j in range(len(i)):\n",
    "                original_features.append(i[j])\n",
    "    # 1차원 array 인 경우\n",
    "    elif isinstance(new_features, list):\n",
    "        for i in range(len(new_features)):\n",
    "            original_features.append(new_features[i])\n",
    "\n",
    "            \n",
    "def get_four_direction_features(pixel, density=0):\n",
    "    row_len = len(pixel)\n",
    "    col_len = len(pixel[0])\n",
    "    out = {x: np.zeros(row_len) for x in (\"N\", \"W\", \"S\", \"E\")}  # 북서남동 각각 28 개씩 있음\n",
    "    transform_ratio = 255 * 1/28\n",
    "    out_features = list()\n",
    "    \n",
    "    # North\n",
    "    for i in range(col_len):\n",
    "        for j in range(row_len):\n",
    "            if pixel[j, i] > density:\n",
    "                result_ = j\n",
    "                out[\"N\"][i] = result_ * transform_ratio\n",
    "                break\n",
    "                \n",
    "    # West\n",
    "    for i in range(row_len):\n",
    "        for j in range(col_len):\n",
    "            if pixel[i, j] > density:\n",
    "                result_ = j\n",
    "                out[\"W\"][i] = result_ * transform_ratio\n",
    "                break\n",
    "                \n",
    "    # South\n",
    "    for i in range(col_len):\n",
    "        for j in range(row_len):\n",
    "            if pixel[(row_len - 1) - j, i] > density:\n",
    "                result_ = (row_len - 1) - j\n",
    "                out[\"S\"][i] = result_ * transform_ratio\n",
    "                break\n",
    "            \n",
    "    # East\n",
    "    for i in range(row_len):\n",
    "        for j in range(col_len):\n",
    "            if pixel[i, (col_len - 1) - j] > density:\n",
    "                result_ = (col_len - 1) - j\n",
    "                out[\"E\"][i] = result_ * transform_ratio\n",
    "                break\n",
    "    \n",
    "    # processing data\n",
    "    for f in out.values():\n",
    "        out_features.append(f.tolist())\n",
    "    \n",
    "    return out_features\n",
    "\n",
    "\n",
    "def get_diagonal_direction_features(pixel, density=0):\n",
    "    row_len = len(pixel)\n",
    "    col_len = len(pixel[0])\n",
    "    out = [[0 for _ in range(2 * row_len - 1)],  # 2\n",
    "           [0 for _ in range(2 * row_len - 1)],  # 3\n",
    "           [0 for _ in range(2 * row_len - 1)],  # 4\n",
    "           [0 for _ in range(2 * row_len - 1)]]  # 1\n",
    "    \n",
    "    # transform_ratio = 255 * 1/28\n",
    "    \n",
    "    # 2사분면\n",
    "    for i in range(row_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - i + j, j] > density:\n",
    "                out[0][i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "    count = 1\n",
    "    for i in range(row_len):\n",
    "        if pixel[i, i] > density:\n",
    "            out[0][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "            break\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for i in range(row_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[j, (col_len - 1) - i + j] > density:\n",
    "                out[0][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "                \n",
    "    # 3사분면\n",
    "    for i in range(row_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[i - j, j] > density:\n",
    "                out[1][i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "    count = 1\n",
    "    for i in range(row_len):\n",
    "        if pixel[(row_len - 1) - i, i] > density:\n",
    "            out[1][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "            break\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for i in range(row_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - j, (col_len - 1) - i + j] > density:\n",
    "                out[1][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "                \n",
    "    # 4사분면\n",
    "    for i in range(col_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[i - j, (col_len - 1) - j] > density:\n",
    "                out[2][i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "    count = 1\n",
    "    for i in range(row_len):\n",
    "        if pixel[(row_len - 1) - i, (col_len - 1) - i] > density:\n",
    "            out[2][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "            break\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for i in range(col_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - j, i - j] > density:\n",
    "                out[2][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "            \n",
    "    # 1사분면\n",
    "    for i in range(col_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[j, i - j] > density:\n",
    "                out[3][i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "    count = 1\n",
    "    for i in range(row_len):\n",
    "        if pixel[i, (col_len - 1) - i] > density:\n",
    "            out[3][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "            break\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for i in range(col_len - 1):\n",
    "        count = 1\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - i + j, (col_len - 1) - j] > density:\n",
    "                out[3][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "                break\n",
    "            count += 1\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def get_length_features(pixel, density=0):\n",
    "    row_len = len(pixel)\n",
    "    col_len = len(pixel[0])\n",
    "    out = {x: np.zeros(row_len) for x in (\"N\", \"W\", \"S\", \"E\")}  # 북서남동 각각 28 개씩 있음\n",
    "    transform_ratio = 255 * 1/28 * 2\n",
    "    out_features = list()\n",
    "\n",
    "    # North\n",
    "    for i in range(col_len):\n",
    "        count = 0\n",
    "        for j in range(row_len):\n",
    "            if pixel[j, i] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[j, i] <= density:\n",
    "                break\n",
    "        out[\"N\"][i] = count * transform_ratio\n",
    "\n",
    "    # West\n",
    "    for i in range(row_len):\n",
    "        count = 0\n",
    "        for j in range(col_len):\n",
    "            if pixel[i, j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[i, j] <= density:\n",
    "                break\n",
    "        out[\"W\"][i] = count * transform_ratio\n",
    "\n",
    "    # South\n",
    "    for i in range(col_len):\n",
    "        count = 0\n",
    "        for j in range(row_len):\n",
    "            if pixel[(row_len - 1) - j, i] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[(row_len - 1) - j, i] <= density:\n",
    "                break\n",
    "        out[\"S\"][i] = count * transform_ratio\n",
    "\n",
    "    # East\n",
    "    for i in range(row_len):\n",
    "        count = 0\n",
    "        for j in range(col_len):\n",
    "            if pixel[i, (col_len - 1) - j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[i, (col_len - 1) - j] <= density:\n",
    "                break\n",
    "        out[\"E\"][i] = count * transform_ratio\n",
    "\n",
    "    # processing data\n",
    "    for f in out.values():\n",
    "        out_features.append(f.tolist())\n",
    "\n",
    "    return out_features\n",
    "\n",
    "\n",
    "def get_diagonal_length_features(pixel, density=0):\n",
    "    row_len = len(pixel)\n",
    "    col_len = len(pixel[0])\n",
    "    out = [[0 for _ in range(2 * row_len - 1)],  # 2\n",
    "           [0 for _ in range(2 * row_len - 1)],  # 3\n",
    "           [0 for _ in range(2 * row_len - 1)],  # 4\n",
    "           [0 for _ in range(2 * row_len - 1)]]  # 1\n",
    "    \n",
    "    # transform_ratio = 255 * 1/28\n",
    "    \n",
    "    # 2사분면\n",
    "    for i in range(row_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - i + j, j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[(row_len - 1) - i + j, j] <= density:\n",
    "                break\n",
    "        out[0][i] = count * (255 * 1 / (i + 1))\n",
    "        \n",
    "    count = 0\n",
    "    for i in range(row_len):\n",
    "        if pixel[i, i] > density:\n",
    "            count += 1\n",
    "        if count > 0 and pixel[i, i] <= density:\n",
    "            break\n",
    "    out[0][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(row_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[j, (col_len - 1) - i + j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[j, (col_len - 1) - i + j] <= density:\n",
    "                break\n",
    "        out[0][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "                \n",
    "    # 3사분면\n",
    "    for i in range(row_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[i - j, j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[i - j, j] <= density:\n",
    "                break\n",
    "        out[1][i] = count * (255 * 1 / (i + 1))\n",
    "        \n",
    "    count = 0\n",
    "    for i in range(row_len):\n",
    "        if pixel[(row_len - 1) - i, i] > density:\n",
    "            count += 1\n",
    "        if count > 0 and pixel[(row_len - 1) - i, i] <= density:\n",
    "            break\n",
    "    out[1][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(row_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - j, (col_len - 1) - i + j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[(row_len - 1) - j, (col_len - 1) - i + j] <= density:\n",
    "                break\n",
    "        out[1][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "                \n",
    "    # 4사분면\n",
    "    for i in range(col_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[i - j, (col_len - 1) - j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[i - j, (col_len - 1) - j] <= density:\n",
    "                break\n",
    "        out[2][i] = count * (255 * 1 / (i + 1))\n",
    "            \n",
    "    count = 0\n",
    "    for i in range(row_len):\n",
    "        if pixel[(row_len - 1) - i, (col_len - 1) - i] > density:\n",
    "            count += 1\n",
    "        if count > 0 and pixel[(row_len - 1) - i, (col_len - 1) - i] <= density:\n",
    "            break\n",
    "    out[2][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(col_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - j, i - j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[(row_len - 1) - j, i - j] <= density:\n",
    "                break\n",
    "        out[2][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "            \n",
    "    # 1사분면\n",
    "    for i in range(col_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[j, i - j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[j, i - j] <= density:\n",
    "                break\n",
    "        out[3][i] = count * (255 * 1 / (i + 1))\n",
    "            \n",
    "    count = 0\n",
    "    for i in range(row_len):\n",
    "        if pixel[i, (col_len - 1) - i] > density:\n",
    "            count += 1\n",
    "        if count > 0 and pixel[i, (col_len - 1) - i] <= density:\n",
    "            break\n",
    "    out[3][row_len - 1] = count * (255 * 1 / (i + 1))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(col_len - 1):\n",
    "        count = 0\n",
    "        for j in range(i + 1):\n",
    "            if pixel[(row_len - 1) - i + j, (col_len - 1) - j] > density:\n",
    "                count += 1\n",
    "            if count > 0 and pixel[(row_len - 1) - i + j, (col_len - 1) - j] <= density:\n",
    "                break\n",
    "        out[3][row_len + i] = count * (255 * 1 / (i + 1))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def get_two_connected_features(pixel):\n",
    "    row_len = len(pixel)\n",
    "    col_len = len(pixel[0])\n",
    "    out = []\n",
    "    transform_ratio = 255 ** 2\n",
    "    margin = 4\n",
    "    \n",
    "    for i in range(margin, row_len - margin + 1):\n",
    "        for j in range(margin, col_len - margin + 1):\n",
    "            out.append([pixel[i, j] * pixel[i - 1, j] / transform_ratio, pixel[i, j] * pixel[i - 1, j + 1] / transform_ratio, pixel[i, j] * pixel[i + 1, j + 1] / transform_ratio])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = list(read(\"testing\",\"./dataset/testing\"))\n",
    "train_set = list(read(\"training\",\"./dataset/training\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "labels['train'] = []\n",
    "labels['test'] = []\n",
    "\n",
    "images = {}\n",
    "images['train'] = []\n",
    "images['test'] = []\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    images['train'].append(list(np.reshape(train_set[i][1], 28*28)))\n",
    "    labels['train'].append(train_set[i][0])\n",
    "\n",
    "test = {}\n",
    "test['images'] = []\n",
    "test['labels'] = []\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    images['test'].append(list(np.reshape(test_set[i][1], 28*28)))\n",
    "    labels['test'].append(test_set[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PCA\n",
    "\"\"\"\n",
    "n_feature = 50\n",
    "\n",
    "end_to_train = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    end_to_train[i] += draw_to_end(np.reshape(images['train'][i], (28, 28)))\n",
    "    \n",
    "end_to_test = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(images['test'])):\n",
    "    end_to_test[i] += draw_to_end(np.reshape(images['test'][i], (28, 28)))\n",
    "    \n",
    "pca2 = PCA(n_components=n_feature)\n",
    "X_train_pca2 = pca2.fit_transform(end_to_train)\n",
    "X_test_pca2 = pca2.transform(end_to_test)\n",
    "\n",
    "end_to_train_by_col = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    end_to_train_by_col[i] += draw_to_end_by_col(np.reshape(images['train'][i], (28, 28)))\n",
    "    \n",
    "end_to_test_by_col = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(images['test'])):\n",
    "    end_to_test_by_col[i] += draw_to_end_by_col(np.reshape(images['test'][i], (28, 28)))\n",
    "    \n",
    "pca3 = PCA(n_components=n_feature)\n",
    "X_train_pca3 = pca3.fit_transform(end_to_train_by_col)\n",
    "X_test_pca3 = pca3.transform(end_to_test_by_col)\n",
    "\n",
    "result_images = {}\n",
    "result_images['train'] = [[] for i in range(len(images['train']))]\n",
    "result_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "###\n",
    "\n",
    "temp_images = {}\n",
    "sc = StandardScaler()\n",
    "\n",
    "n_feature_f = 80\n",
    "\n",
    "pca1 = PCA(n_components=n_feature_f)\n",
    "X_train_pca1 = pca1.fit_transform(images['train'])\n",
    "X_test_pca1 = pca1.transform(images['test'])\n",
    "\n",
    "temp_images['train'] = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(X_train_pca1)):\n",
    "    temp_images['train'][i] += new_feature(X_train_pca1[i], n_feature_f)\n",
    "    \n",
    "temp_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(X_test_pca1)):\n",
    "    temp_images['test'][i] += new_feature(X_test_pca1[i], n_feature_f)\n",
    "    \n",
    "sc.fit(temp_images['train'])\n",
    "temp_images['train'] = sc.transform(temp_images['train'])\n",
    "temp_images['test'] = sc.transform(temp_images['test'])\n",
    "\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(temp_images['train'][i])\n",
    "    \n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(temp_images['test'][i])\n",
    "\n",
    "\n",
    "# type(temp_images['train'][i])\n",
    "\n",
    "\n",
    "temp_images['train'] = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(X_train_pca1)):\n",
    "    temp_images['train'][i] += new_feature2(X_train_pca1[i], n_feature_f)\n",
    "    \n",
    "temp_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(X_test_pca1)):\n",
    "    temp_images['test'][i] += new_feature2(X_test_pca1[i], n_feature_f)\n",
    "    \n",
    "sc.fit(temp_images['train'])\n",
    "temp_images['train'] = sc.transform(temp_images['train'])\n",
    "temp_images['test'] = sc.transform(temp_images['test'])\n",
    "\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(temp_images['train'][i])\n",
    "    \n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(temp_images['test'][i])\n",
    "    \n",
    "# end-to 곱하기 연산\n",
    "temp_images['train'] = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(X_train_pca2)):\n",
    "    temp_images['train'][i] += new_feature(X_train_pca2[i], n_feature)\n",
    "    \n",
    "temp_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(X_test_pca2)):\n",
    "    temp_images['test'][i] += new_feature(X_test_pca2[i], n_feature)\n",
    "    \n",
    "sc.fit(temp_images['train'])\n",
    "temp_images['train'] = sc.transform(temp_images['train'])\n",
    "temp_images['test'] = sc.transform(temp_images['test'])\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(temp_images['train'][i])\n",
    "    \n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(temp_images['test'][i])\n",
    "    \n",
    "# end-to 더하기 연산\n",
    "temp_images['train'] = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(X_train_pca2)):\n",
    "    temp_images['train'][i] += new_feature2(X_train_pca2[i], n_feature)\n",
    "    \n",
    "temp_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(X_test_pca2)):\n",
    "    temp_images['test'][i] += new_feature2(X_test_pca2[i], n_feature)\n",
    "    \n",
    "sc.fit(temp_images['train'])\n",
    "temp_images['train'] = sc.transform(temp_images['train'])\n",
    "temp_images['test'] = sc.transform(temp_images['test'])\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(temp_images['train'][i])\n",
    "    \n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(temp_images['test'][i])\n",
    "    \n",
    "# end-to_by_col 곱하기 연산\n",
    "temp_images['train'] = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(X_train_pca3)):\n",
    "    temp_images['train'][i] += new_feature(X_train_pca3[i], n_feature)\n",
    "    \n",
    "temp_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(X_test_pca3)):\n",
    "    temp_images['test'][i] += new_feature(X_test_pca3[i], n_feature)\n",
    "    \n",
    "sc.fit(temp_images['train'])\n",
    "temp_images['train'] = sc.transform(temp_images['train'])\n",
    "temp_images['test'] = sc.transform(temp_images['test'])\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(temp_images['train'][i])\n",
    "    \n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(temp_images['test'][i])\n",
    "\n",
    "# end-to_by_col 더하기 연산\n",
    "temp_images['train'] = [[] for i in range(len(images['train']))]\n",
    "\n",
    "for i in range(len(X_train_pca3)):\n",
    "    temp_images['train'][i] += new_feature2(X_train_pca3[i], n_feature)\n",
    "    \n",
    "temp_images['test'] = [[] for i in range(len(images['test']))]\n",
    "\n",
    "for i in range(len(X_test_pca3)):\n",
    "    temp_images['test'][i] += new_feature2(X_test_pca3[i], n_feature)\n",
    "    \n",
    "sc.fit(temp_images['train'])\n",
    "temp_images['train'] = sc.transform(temp_images['train'])\n",
    "temp_images['test'] = sc.transform(temp_images['test'])\n",
    "\n",
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(temp_images['train'][i])\n",
    "    \n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(temp_images['test'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del temp_images # 필요없는 것 지움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract feature\n",
    "filter = np.load('./filter.npy')\n",
    "def extract_feature(image_input):\n",
    "    image = copy.copy(image_input)\n",
    "    image = image.flatten()\n",
    "    image = np.asarray(image, dtype='float')\n",
    "    new_feature=[]\n",
    "    for number in range(0,10):\n",
    "        new_feature .append(np.dot(image,filter[number]))\n",
    "    \n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_add = {}\n",
    "train_add['images'] = []\n",
    "train_add['labels'] = []\n",
    "for i in range(len(train_set)):\n",
    "    image = []\n",
    "    \n",
    "    diagonal_direction_features = get_diagonal_direction_features(train_set[i][1], density=150)\n",
    "    add_new_features(image, diagonal_direction_features)\n",
    "    diagonal_length_features = get_diagonal_length_features(train_set[i][1], density=20)\n",
    "    add_new_features(image, diagonal_length_features)\n",
    "    direction_features = get_four_direction_features(train_set[i][1], density=150)\n",
    "    add_new_features(image, direction_features)\n",
    "    length_features = get_length_features(train_set[i][1], density=20)\n",
    "    add_new_features(image, length_features)\n",
    "\n",
    "    \n",
    "#     for line in train_set[i][1]:\n",
    "#         image += list(line)\n",
    "    \n",
    "    train_add['images'].append(image)\n",
    "    train_add['labels'].append(train_set[i][0])\n",
    "\n",
    "test_add = {}\n",
    "test_add['images'] = []\n",
    "test_add['labels'] = []\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    image = []\n",
    "    \n",
    "    diagonal_direction_features = get_diagonal_direction_features(test_set[i][1], density=150)\n",
    "    add_new_features(image, diagonal_direction_features)\n",
    "    diagonal_length_features = get_diagonal_length_features(test_set[i][1], density=20)\n",
    "    add_new_features(image, diagonal_length_features)\n",
    "    direction_features = get_four_direction_features(test_set[i][1], density=150)\n",
    "    add_new_features(image, direction_features)\n",
    "    length_features = get_length_features(test_set[i][1], density=20)\n",
    "    add_new_features(image, length_features)\n",
    "\n",
    "\n",
    "#     for line in train_set[i][1]:\n",
    "#         image += list(line)\n",
    "    \n",
    "    \n",
    "    test_add['images'].append(image)\n",
    "    test_add['labels'].append(test_set[i][0])\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_add['images'])\n",
    "std_images = {}\n",
    "std_images['train'] = sc.transform(train_add['images'])\n",
    "std_images['test'] = sc.transform(test_add['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(std_images['train'][i])\n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(std_images['test'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_add = {}\n",
    "train_add['images'] = []\n",
    "train_add['labels'] = []\n",
    "for i in range(len(train_set)):\n",
    "    image = []\n",
    "    \n",
    "    eeee = extract_feature(train_set[i][1])\n",
    "    add_new_features(image, eeee)\n",
    "    \n",
    "    train_add['images'].append(image)\n",
    "    train_add['labels'].append(train_set[i][0])\n",
    "\n",
    "test_add = {}\n",
    "test_add['images'] = []\n",
    "test_add['labels'] = []\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    image = []\n",
    "    \n",
    "    eeee = extract_feature(test_set[i][1])\n",
    "    add_new_features(image, eeee)\n",
    "    \n",
    "    test_add['images'].append(image)\n",
    "    test_add['labels'].append(test_set[i][0])\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_add['images'])\n",
    "std_images = {}\n",
    "std_images['train'] = sc.transform(train_add['images'])\n",
    "std_images['test'] = sc.transform(test_add['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(std_images['train'][i])\n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(std_images['test'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_add = {}\n",
    "train_add['images'] = []\n",
    "train_add['labels'] = []\n",
    "for i in range(len(train_set)):\n",
    "    image = []\n",
    "    \n",
    "    demension = get_two_connected_features(train_set[i][1])\n",
    "    add_new_features(image, demension)\n",
    "    \n",
    "    train_add['images'].append(image)\n",
    "    train_add['labels'].append(train_set[i][0])\n",
    "\n",
    "test_add = {}\n",
    "test_add['images'] = []\n",
    "test_add['labels'] = []\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    image = []\n",
    "    \n",
    "    demension = get_two_connected_features(test_set[i][1])\n",
    "    add_new_features(image, demension)\n",
    "    \n",
    "    test_add['images'].append(image)\n",
    "    test_add['labels'].append(test_set[i][0])\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_add['images'])\n",
    "std_images = {}\n",
    "std_images['train'] = sc.transform(train_add['images'])\n",
    "std_images['test'] = sc.transform(test_add['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(images['train'])):\n",
    "    result_images['train'][i] += list(std_images['train'][i])\n",
    "for i in range(len(images['test'])):\n",
    "    result_images['test'][i] += list(std_images['test'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_images['train'] = np.array(result_images['train'])\n",
    "result_images['test'] = np.array(result_images['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time : 425.8047604560852\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = StochasticClassifier(lamb=0.0005, eta=0.5, random_state=1, b_size=300, n_iter=10000)\n",
    "clf.fit(result_images[\"train\"], labels['train'])\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time : {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.89\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(result_images[\"test\"])\n",
    "print(\"Accuracy : {}\".format(accuracy_score(labels['test'], pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
